# Prompt engineering

Prompt engineering is the practice of giving an AI model specific instructions to produce the results you want.

## Best Practices For Prompt Crafting With GitHub Copilot

- **Iterate on and recraft your prompts**: If your initial prompt doesn't give you what you want, delete the generated code suggestion, edit your comment or prompt with more details, or, by saying it another way, with more details and examples, and then try again. By providing a big picture description within your prompt for a section of code or a new file that is completely blank**, this big picture description to set the stage will help GitHub Copilot provide better results. Also, when you're crafting your prompts, keep them simple and specific to the point with the right amount of description. Providing a series of clear steps to define what we want. I think of this as more like a recipe with a list of separate ingredients or steps that we're sending to GitHub Copilot instead of a long paragraph that includes everything. 

- **The second tip or best practice is to keep a couple of relevant tabs open in your editor**: now GitHub Copilot uses a technique called neighboring tabs that allows the AI pair programmer to contextualize your code by processing all of the files open in your IDE instead of just the single file that you're working on. By opening all files relevant to your project, GitHub Copilot will automatically comb through all of the data and find matching pieces of code between your open files and the code around your cursor and then add those matches to the prompt response if it's relevant. This allows you to GitHub more complete response that provides code suggestions and explanations of code that not only are applied to one file but multiple files within the same prompt response.

- **Another tip or best practice is to provide GitHub Copilot examples within your prompts**: learning from examples is not only useful for humans, but also for generative AI tools like GitHub Copilot. So in addition to providing steps within your prompts, you can show GitHub Copilot what you want it to do with examples in your preferred coding style. While GitHub Copilot is using an AI model that is already trained on a large amount of data, providing examples to GitHub Copilot will help it understand the context and constraints of a particular code snippet. Now this concept of providing examples to AI models is actually a common practice in machine learning, and some popular approaches are called **zero‑shot learning**, **one‑shot learning**, and **few‑shot learning**. 
    - **Zero‑shot learning**: imagine you have a friend who loves animals but has never seen a zebra before. Now if you show your friend a picture of a zebra and ask what animal is this and your friend guesses it's a zebra without any prior information, that's like zero‑shot learning. It's making a correct guess about something without any training or examples beforehand. 
    
    - **One‑shot learning**: now say your friend has seen a few pictures of zebras before but not many. If you show a new picture of a zebra and your friend can correctly say it's a zebra based on just that one additional picture, it's like one‑shot learning. It's learning from a very small amount of information. Now, with few‑shot learning, if your friend has seen a bunch of pictures of different animals including zebras and you show a new zebra picture, they can still recognize it even though they haven't seen many zebras before. It's learning from a small but still more than one set of examples. So in summary, **zero‑shot is like making a good guess about something completely new, one‑shot is learning from just one example, and few‑shot is learning from a small group of examples but more than one.**

## LLMs and OpenAIs Codex That Powers GitHub Copilot

LLMs refer to a type of artificial intelligence model that is trained on massive amounts of text data to understand and generate human-like language. These models use machine learning techniques, particularly deep learning, to process and analyze language patterns, enabling them to perform various natural language processing taks.